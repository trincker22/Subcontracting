---
title: "MakeReadable"
output: html_document
date: "2025-08-27"
---

```{r setup, include=FALSE}

library(readxl)
library(dplyr)
library(stringr)
library(tidyr)
library(stringr)
library(dplyr)
library(tidyr)
library(purrr)
library(stringdist)
options(scipen =999)

```

# Dictionary From DAU

```{r}


dict_path <- here("Data", "acronymdict.RDS")

if (!file.exists(dict_path)) {

raw <- read_xlsx(xlsx_path, col_names = F)
colname <- names(raw)[which.max(colSums(!is.na(raw)))]
lines <- as.character(raw[[colname]])
lines <- lines[!is.na(lines)]
lines <- str_squish(lines)
lines <- lines[nzchar(lines)]

split_acr <- function(txt) {
  m <- regexec("^(\\S{2,15})\\s+(.+)$", txt)
  r <- regmatches(txt, m)[[1]]
  if (length(r) == 3) {
    acr <- toupper(trimws(r[2]))
    exp <- trimws(r[3])
    return(data.frame(acr = acr, exp = exp, stringsAsFactors = FALSE))
  } else {
    return(data.frame(acr = NA, exp = NA, stringsAsFactors = FALSE))
  }
}

acr_tbl <- bind_rows(lapply(lines, split_acr)) %>%
  filter(!is.na(acr), !is.na(exp), nzchar(acr), nzchar(exp))


acr_tbl_split <- acr_tbl %>%
  mutate(exp = str_split(exp, ";")) %>%
  unnest(exp) %>%
  mutate(exp = str_squish(exp)) %>%
  filter(exp != "")

acr_tbl_split <- distinct(acr_tbl_split, acr, exp)


head(acr_tbl_split, 20)


saveRDS(acr_tbl_split, here(dict_path))

} else {
  dict <- readRDS(dict_path)
}


names(contracts)




```

# Build From Corpus 

```{r}

catalog_markers <- c("PN","NSN","CLIN","NIIN","SDRL","FAI","MTBF","BOM","EOL","CAGE","P/N","S/N")
connectors <- c("AND","OF","THE","FOR","IN","ON","WITH","TO","BY","AT","FROM","A","AN")


looks_like_acronym <- function(acr) {

  grepl("^[A-Z0-9][A-Z0-9&\\.\\-]{1,9}$", acr) &&
    (str_count(acr, "[A-Z]") >= 2)
}

normalize_phrase <- function(x) {
  x %>%
    toupper() %>%
    str_replace_all("&", " AND ") %>%
    str_replace_all("[ ]*/[ ]*", "/") %>%      # keep slashes tight
    str_replace_all("[^A-Z0-9/ \\-]", " ") %>% # drop punct except / and -
    str_replace_all("\\s+", " ") %>%
    str_squish()
}


initials_from_phrase <- function(phrase, drop_words = connectors) {
  p <- normalize_phrase(phrase)
  toks <- unlist(str_split(p, "\\s+"))
  toks <- toks[!(toks %in% drop_words)]
  toks <- toks[nzchar(toks)]
  if (length(toks) == 0) return(list(init = "", n_tokens = 0))
  init <- paste0(substr(toks, 1, 1), collapse = "")
  list(init = init, n_tokens = length(toks))
}

pat_exp_acr <- "(?<exp>[A-Za-z][A-Za-z0-9/&\\-\\. ,]+?)\\s*\\((?<acr>[A-Z0-9][A-Z0-9&\\.\\-]{1,9})\\)"
pat_acr_exp <- "(?<acr>[A-Z0-9][A-Z0-9&\\.\\-]{1,9})\\s*\\((?<exp>[A-Za-z][A-Za-z0-9/&\\-\\. ,]+?)\\)"

extract_pairs <- function(txt) {
  # EXP (ACR)
  m1 <- str_match_all(txt, pat_exp_acr)[[1]]
  df1 <- if (nrow(m1)) tibble(acr = m1[, "acr"], exp = m1[, "exp"]) else tibble(acr=character(),exp=character())
  # ACR (EXP)
  m2 <- str_match_all(txt, pat_acr_exp)[[1]]
  df2 <- if (nrow(m2)) tibble(acr = m2[, "acr"], exp = m2[, "exp"]) else tibble(acr=character(),exp=character())
  bind_rows(df1, df2)
}


mine_acronym_pairs <- function(texts) {

  cand <- map_dfr(texts, extract_pairs) %>%
    mutate(acr = toupper(str_squish(acr)),
           exp = str_squish(exp)) %>%
    filter(nchar(acr) >= 2, nchar(exp) >= 3)

  if (nrow(cand) == 0) return(cand)

  cand <- cand %>%
    filter(!acr %in% catalog_markers) %>%
    rowwise() %>%
    mutate(
      valid_shape = looks_like_acronym(acr),
      init_info   = list(initials_from_phrase(exp)),
      init        = init_info$init,
      n_tokens    = init_info$n_tokens
    ) %>%
    ungroup() %>%
    select(-init_info)


  hi_conf <- cand %>%
    filter(
      valid_shape,
      n_tokens >= nchar(acr),  # expansion must have at least as many tokens as letters
      init == acr              # initials EXACTLY match acronym
    ) %>%
    distinct(acr, exp)

  hi_conf
}



hi_conf_pairs <- mine_acronym_pairs(texts)
head(hi_conf_pairs, 20)



normalize_exp <- function(x) {
  x %>%
    toupper() %>%
    str_replace_all("[ ]*/[ ]*", " / ") %>%     # normalize slashes
    str_replace_all("[ ]*-[ ]*", "-") %>%       # normalize hyphens
    str_replace_all("\\s+", " ") %>%
    str_squish()
}

dict_all <- hi_conf_pairs %>%
  mutate(exp_norm = normalize_exp(exp)) %>%
  count(acr, exp_norm, name = "freq", sort = TRUE) %>%
  mutate(exp = exp_norm) %>%
  select(acr, exp, freq)


collapse_within_acr <- function(df, max_dist = 2) {
  if (nrow(df) <= 1) return(df)
  keep <- rep(TRUE, nrow(df))
  for (i in seq_len(nrow(df))) {
    if (!keep[i]) next
    for (j in seq((i+1), nrow(df))) {
      if (!keep[j]) next
      if (stringdist::stringdist(df$exp[i], df$exp[j], method = "osa") <= max_dist) {
        if (df$freq[j] > df$freq[i] ||
            (df$freq[j] == df$freq[i] && nchar(df$exp[j]) > nchar(df$exp[i]))) {
          df$exp[i]  <- df$exp[j]
          df$freq[i] <- df$freq[j]
        }
        keep[j] <- FALSE
      }
    }
  }
  df[keep, , drop = FALSE]
}
dict_all <- dict_all %>%
  group_by(acr) %>%
  group_modify(~ collapse_within_acr(.x)) %>%
  ungroup()


dict_primary <- dict_all %>%
  group_by(acr) %>%
  arrange(desc(freq), desc(nchar(exp))) %>%
  slice(1) %>%
  ungroup() %>%
  select(acr, exp)


dict_all %>% filter(acr %in% c("EHM","TIS"))
dict_primary %>% filter(acr %in% c("EHM","TIS"))

# write.csv(dict_all, "Data/acronyms_mined_all.csv", row.names = FALSE)
# write.csv(dict_primary, "Data/acronyms_mined_primary.csv", row.names = FALSE)


```

Merge
```{r}

dict_merged <- bind_rows(
  dict %>% mutate(source = "DAU"),
  dict %>% 
    filter(!acr %in% acr_dict_dau$acr) %>% 
    mutate(source = "mined")
)

dict_all_merged <- bind_rows(
  acr_dict_dau %>% mutate(source = "DAU", freq = NA),
  dict_all %>% filter(!acr %in% acr_dict_dau$acr) %>% mutate(source = "mined")
)


```



```{r}



```


